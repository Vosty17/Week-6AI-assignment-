{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "a2a8f6de-709f-4468-8719-92fe104aa293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from river import tree, metrics, stream\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "2952b366-98b2-4e93-946a-18f08285c62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "Step 1:DATA LOADING\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*55)\n",
    "print('Step 1:DATA LOADING')\n",
    "print(\"=\"*55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "e2872d5e-113f-4a31-b786-9b54408ba038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('Crop_recommendation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "a649a08c-a24a-4e00-ba75-db54baa97628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "Step 2:DATA EXPLORATION\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*55)\n",
    "print('Step 2:DATA EXPLORATION')\n",
    "print(\"=\"*55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "899415c0-e2d1-498d-bba8-bb128315f167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (2200, 8)\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>ph</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>20.879744</td>\n",
       "      <td>82.002744</td>\n",
       "      <td>6.502985</td>\n",
       "      <td>202.935536</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>58</td>\n",
       "      <td>41</td>\n",
       "      <td>21.770462</td>\n",
       "      <td>80.319644</td>\n",
       "      <td>7.038096</td>\n",
       "      <td>226.655537</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>44</td>\n",
       "      <td>23.004459</td>\n",
       "      <td>82.320763</td>\n",
       "      <td>7.840207</td>\n",
       "      <td>263.964248</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>26.491096</td>\n",
       "      <td>80.158363</td>\n",
       "      <td>6.980401</td>\n",
       "      <td>242.864034</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>20.130175</td>\n",
       "      <td>81.604873</td>\n",
       "      <td>7.628473</td>\n",
       "      <td>262.717340</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    N   P   K  temperature   humidity        ph    rainfall label\n",
       "0  90  42  43    20.879744  82.002744  6.502985  202.935536  rice\n",
       "1  85  58  41    21.770462  80.319644  7.038096  226.655537  rice\n",
       "2  60  55  44    23.004459  82.320763  7.840207  263.964248  rice\n",
       "3  74  35  40    26.491096  80.158363  6.980401  242.864034  rice\n",
       "4  78  42  42    20.130175  81.604873  7.628473  262.717340  rice"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label distribution:\n",
      "label\n",
      "rice           100\n",
      "maize          100\n",
      "jute           100\n",
      "cotton         100\n",
      "coconut        100\n",
      "papaya         100\n",
      "orange         100\n",
      "apple          100\n",
      "muskmelon      100\n",
      "watermelon     100\n",
      "grapes         100\n",
      "mango          100\n",
      "banana         100\n",
      "pomegranate    100\n",
      "lentil         100\n",
      "blackgram      100\n",
      "mungbean       100\n",
      "mothbeans      100\n",
      "pigeonpeas     100\n",
      "kidneybeans    100\n",
      "chickpea       100\n",
      "coffee         100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display dataset info\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "8652c0d3-e316-4a9d-9199-d24757d2db48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "Step 3:DATA PREPROCESSING\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*55)\n",
    "print('Step 3:DATA PREPROCESSING')\n",
    "print(\"=\"*55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "07efccb6-166e-441b-b61a-16a9eb6bff68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing complete!\n",
      "Training set: (1760, 7), Test set: (440, 7)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "df['label_encoded'] = le.fit_transform(df['label'])\n",
    "joblib.dump(le, 'label_encoder.joblib')\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(['label', 'label_encoded'], axis=1)\n",
    "y = df['label_encoded']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "print(\"Data preprocessing complete!\")\n",
    "print(f\"Training set: {X_train_scaled.shape}, Test set: {X_test_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "6da43ac4-6113-42d5-8c30-a63434f6496d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "Step 4:MODEL TRAINING\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*55)\n",
    "print('Step 4:MODEL TRAINING')\n",
    "print(\"=\"*55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "d8da5c2f-63ac-45bd-bb22-3c50ce89ba25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully! Accuracy: 0.9886\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       1.00      1.00      1.00        20\n",
      "      banana       1.00      1.00      1.00        18\n",
      "   blackgram       1.00      0.94      0.97        17\n",
      "    chickpea       1.00      1.00      1.00        22\n",
      "     coconut       1.00      1.00      1.00        20\n",
      "      coffee       1.00      1.00      1.00        21\n",
      "      cotton       1.00      1.00      1.00        19\n",
      "      grapes       1.00      1.00      1.00        25\n",
      "        jute       0.86      1.00      0.92        18\n",
      " kidneybeans       1.00      1.00      1.00        21\n",
      "      lentil       0.94      1.00      0.97        17\n",
      "       maize       0.94      1.00      0.97        15\n",
      "       mango       1.00      1.00      1.00        19\n",
      "   mothbeans       1.00      0.93      0.97        15\n",
      "    mungbean       1.00      1.00      1.00        18\n",
      "   muskmelon       1.00      1.00      1.00        17\n",
      "      orange       1.00      1.00      1.00        20\n",
      "      papaya       1.00      1.00      1.00        24\n",
      "  pigeonpeas       1.00      1.00      1.00        22\n",
      " pomegranate       1.00      1.00      1.00        23\n",
      "        rice       1.00      0.87      0.93        23\n",
      "  watermelon       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           0.99       440\n",
      "   macro avg       0.99      0.99      0.99       440\n",
      "weighted avg       0.99      0.99      0.99       440\n",
      "\n",
      "Historical dataset saved for continuous learning\n"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "# Initialize and train model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save initial model\n",
    "joblib.dump(model, 'initial_model.joblib')\n",
    "joblib.dump(X_train.columns.tolist(),'original_columns.joblib')\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Model trained successfully! Accuracy: {acc:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "# Create historical dataset\n",
    "df.to_csv('sensor_history.csv', index=False)\n",
    "print(\"Historical dataset saved for continuous learning\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "ea1d4f00-e7ee-447a-b951-67a5f0036670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "Step 5:CONTINUOUS LEARNING SYSTEM SETUPS\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*55)\n",
    "print('Step 5:CONTINUOUS LEARNING SYSTEM SETUPS')\n",
    "print(\"=\"*55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "119621f2-72fb-48c3-bf2c-d8966a59d41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "Step 5:INITIALIZE LEARNING SYSTEM\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*55)\n",
    "print('Step 5:INITIALIZE LEARNING SYSTEM')\n",
    "print(\"=\"*55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "33c6f8b1-60d3-4c71-ba2f-4ac3bda5cdf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')  # Temporarily suppress warnings for cleaner output\n",
    "from river import tree, metrics, stream\n",
    "\n",
    "class ContinuousLearningSystem:\n",
    "    def __init__(self):\n",
    "        # Load preprocessing objects\n",
    "        self.scaler = joblib.load('scaler.joblib')\n",
    "        self.label_encoder = joblib.load('label_encoder.joblib')\n",
    "        \n",
    "        # Initialize online model\n",
    "        self.online_model = tree.HoeffdingTreeClassifier()\n",
    "        self.metric = metrics.Accuracy()\n",
    "        self.last_retrain = datetime.now()\n",
    "        \n",
    "        # Initialize with historical data if available\n",
    "        if os.path.exists('sensor_history.csv'):\n",
    "            self.initialize_with_historical_data()\n",
    "    \n",
    "    def initialize_with_historical_data(self):\n",
    "        \"\"\"Load historical data and train model incrementally\"\"\"\n",
    "        df_hist = pd.read_csv('sensor_history.csv')\n",
    "        X_hist = df_hist.drop(['label', 'label_encoded'], axis=1, errors='ignore')\n",
    "        y_hist = df_hist['label_encoded'] if 'label_encoded' in df_hist else self.label_encoder.transform(df_hist['label'])\n",
    "        \n",
    "        # Train online model incrementally\n",
    "        for i, (xi, yi) in enumerate(stream.iter_pandas(X_hist, y_hist)):\n",
    "            # Ensure xi is in correct format (dict)\n",
    "            if not isinstance(xi, dict):\n",
    "                xi = xi.to_dict() if hasattr(xi, 'to_dict') else dict(zip(X_hist.columns, xi))\n",
    "            \n",
    "            xi_scaled = self._scale_features(xi)\n",
    "            self.online_model.learn_one(xi_scaled, yi)\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print(f\"Processed {i+1} historical samples\")\n",
    "        \n",
    "        print(f\"Online model initialized with {len(X_hist)} historical samples\")\n",
    "    \n",
    "    def _scale_features(self, features):\n",
    "        \"\"\"Convert features to dict and scale them\"\"\"\n",
    "        # Ensure features is a dictionary\n",
    "        if not isinstance(features, dict):\n",
    "            if hasattr(features, 'to_dict'):\n",
    "                features = features.to_dict()\n",
    "            else:\n",
    "                features = dict(zip(self.scaler.feature_names_in_, features))\n",
    "        \n",
    "        # Scale features and return as dict\n",
    "        scaled_values = self.scaler.transform([[features[col] for col in self.scaler.feature_names_in_]])[0]\n",
    "        return {col: scaled_values[i] for i, col in enumerate(self.scaler.feature_names_in_)}\n",
    "    \n",
    "    def predict(self, sensor_data):\n",
    "        \"\"\"Make prediction based on sensor input\"\"\"\n",
    "        scaled_features = self._scale_features(sensor_data)\n",
    "        prediction = self.online_model.predict_one(scaled_features)\n",
    "        return self.label_encoder.inverse_transform([prediction])[0]\n",
    "    \n",
    "    def update_model(self, sensor_data, actual_crop):\n",
    "        \"\"\"Update model with new labeled data\"\"\"\n",
    "        # Encode crop label\n",
    "        actual_label = self.label_encoder.transform([actual_crop])[0]\n",
    "        \n",
    "        # Scale features\n",
    "        scaled_features = self._scale_features(sensor_data)\n",
    "        \n",
    "        # Update model\n",
    "        self.online_model.learn_one(scaled_features, actual_label)\n",
    "        \n",
    "        # Update history\n",
    "        self._update_history(sensor_data, actual_crop, actual_label)\n",
    "        \n",
    "        # Periodic retraining\n",
    "        if (datetime.now() - self.last_retrain).days >= 7:\n",
    "            self.full_retrain()\n",
    "            self.last_retrain = datetime.now()\n",
    "    \n",
    "    def _update_history(self, sensor_data, actual_crop, actual_label):\n",
    "        \"\"\"Append new data to historical dataset\"\"\"\n",
    "        # Convert to dictionary format\n",
    "        if isinstance(sensor_data, dict):\n",
    "            new_entry = sensor_data.copy()\n",
    "        elif hasattr(sensor_data, 'to_dict'):\n",
    "            new_entry = sensor_data.to_dict()\n",
    "        else:\n",
    "            new_entry = dict(zip(self.scaler.feature_names_in_, sensor_data))\n",
    "            \n",
    "        new_entry.update({\n",
    "            'label': actual_crop,\n",
    "            'label_encoded': actual_label\n",
    "        })\n",
    "        \n",
    "        # Append to history\n",
    "        if os.path.exists('sensor_history.csv'):\n",
    "            hist_df = pd.read_csv('sensor_history.csv')\n",
    "            updated_df = pd.concat([hist_df, pd.DataFrame([new_entry])], ignore_index=True)\n",
    "        else:\n",
    "            updated_df = pd.DataFrame([new_entry])\n",
    "        \n",
    "        updated_df.to_csv('sensor_history.csv', index=False)\n",
    "    \n",
    "    def full_retrain(self):\n",
    "        \"\"\"Periodic full retraining with all historical data\"\"\"\n",
    "        print(\"Starting full retraining...\")\n",
    "        df_hist = pd.read_csv('sensor_history.csv')\n",
    "        X_hist = df_hist.drop(['label', 'label_encoded'], axis=1)\n",
    "        y_hist = df_hist['label_encoded']\n",
    "        \n",
    "        # Reinitialize model\n",
    "        self.online_model = tree.HoeffdingTreeClassifier()\n",
    "        \n",
    "        # Retrain with all data\n",
    "        for xi, yi in stream.iter_pandas(X_hist, y_hist):\n",
    "            # Ensure xi is in correct format (dict)\n",
    "            if not isinstance(xi, dict):\n",
    "                xi = xi.to_dict() if hasattr(xi, 'to_dict') else dict(zip(X_hist.columns, xi))\n",
    "            \n",
    "            xi_scaled = self._scale_features(xi)\n",
    "            self.online_model.learn_one(xi_scaled, yi)\n",
    "        \n",
    "        print(f\"Model retrained with {len(X_hist)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "77b04e7b-4d2c-4414-9f9f-215240d51c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1 historical samples\n",
      "Processed 101 historical samples\n",
      "Processed 201 historical samples\n",
      "Processed 301 historical samples\n",
      "Processed 401 historical samples\n",
      "Processed 501 historical samples\n",
      "Processed 601 historical samples\n",
      "Processed 701 historical samples\n",
      "Processed 801 historical samples\n",
      "Processed 901 historical samples\n",
      "Processed 1001 historical samples\n",
      "Processed 1101 historical samples\n",
      "Processed 1201 historical samples\n",
      "Processed 1301 historical samples\n",
      "Processed 1401 historical samples\n",
      "Processed 1501 historical samples\n",
      "Processed 1601 historical samples\n",
      "Processed 1701 historical samples\n",
      "Processed 1801 historical samples\n",
      "Processed 1901 historical samples\n",
      "Processed 2001 historical samples\n",
      "Processed 2101 historical samples\n",
      "Online model initialized with 2200 historical samples\n",
      "Continuous learning system initialized!\n"
     ]
    }
   ],
   "source": [
    "cl_system = ContinuousLearningSystem()\n",
    "print(\"Continuous learning system initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "aaa687e0-0503-4152-856e-5097d73385cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VirtualIoTDevice:\n",
    "    def __init__(self, learning_system):\n",
    "        self.learning_system = learning_system\n",
    "        self.sensors = {\n",
    "            'N': np.random.randint(0, 140),\n",
    "            'P': np.random.randint(5, 145),\n",
    "            'K': np.random.randint(5, 205),\n",
    "            'temperature': np.random.uniform(8, 44),\n",
    "            'humidity': np.random.uniform(14, 99),\n",
    "            'ph': np.random.uniform(3.5, 9.9),\n",
    "            'rainfall': np.random.uniform(20, 300)\n",
    "        }\n",
    "    \n",
    "    def read_sensors(self):\n",
    "        \"\"\"Simulate sensor readings with small random variations\"\"\"\n",
    "        new_readings = {}\n",
    "        for key, value in self.sensors.items():\n",
    "            # Add Â±5% variation to simulate real readings\n",
    "            variation = np.random.uniform(-0.05, 0.05)\n",
    "            new_value = max(0, value * (1 + variation))\n",
    "            new_readings[key] = round(new_value, 2)\n",
    "        return new_readings\n",
    "    \n",
    "    def display_recommendation(self, recommendation):\n",
    "        \"\"\"Display recommendation nicely\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Recommended crop: {recommendation}\")\n",
    "        print(\"=\"*50)\n",
    "    \n",
    "    def run(self, days=30):\n",
    "        \"\"\"Simulate device operation over time\"\"\"\n",
    "        for day in range(1, days+1):\n",
    "            print(f\"\\n{'='*30}\")\n",
    "            print(f\"DAY {day} - MORNING READING\")\n",
    "            print(f\"{'='*30}\")\n",
    "            \n",
    "            # Morning reading\n",
    "            sensor_data = self.read_sensors()\n",
    "            print(\"Sensor Readings:\")\n",
    "            for k, v in sensor_data.items():\n",
    "                print(f\"- {k}: {v}\")\n",
    "            \n",
    "            # Get recommendation\n",
    "            recommendation = self.learning_system.predict(sensor_data)\n",
    "            self.display_recommendation(recommendation)\n",
    "            \n",
    "            # Simulate farmer feedback (once every 3 days)\n",
    "            if day % 3 == 0:\n",
    "                print(\"\\nFARMER FEEDBACK RECEIVED\")\n",
    "                # In real system, this would come from farmer input\n",
    "                # Here we'll use a simple simulation\n",
    "                actual_crop = 'rice'  # \n",
    "                #Simulated farmer feedback\n",
    "                print(f\"Farmer planted: {actual_crop}\")\n",
    "                # Update model\n",
    "                self.learning_system.update_model(sensor_data, actual_crop)\n",
    "                print(\"Model updated with new data!\")\n",
    "            # Wait until next day\n",
    "            time.sleep(1)  # Simulate daily interval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "7d4ad069-4d8a-4ac0-945e-f485aea0dfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "Step 6:MAIN DEPLOYMENT\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*55)\n",
    "print('Step 6:MAIN DEPLOYMENT')\n",
    "print(\"=\"*55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "a13dfd56-571f-4524-92bc-c27dd50f5601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Initialize system\n",
    "    cl_system = ContinuousLearningSystem()\n",
    "    device = VirtualIoTDevice(cl_system)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"IoT CROP RECOMMENDATION SYSTEM ACTIVATED\")\n",
    "    print(\"Initial Model Loaded | Continuous Learning Active\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Run simulation\n",
    "    try:\n",
    "        device.run(days=7)  # Simulate 7 days\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nSystem interrupted by user\")\n",
    "    \n",
    "    # Save final state\n",
    "    joblib.dump(cl_system.online_model, 'online_model.joblib')\n",
    "    print(\"\\nSystem shutdown. Model saved for next session.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "60973f56-c8f6-41b2-9dc4-67b542d84a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "Step 7:RUN THE SYSTEM\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*55)\n",
    "print('Step 7:RUN THE SYSTEM')\n",
    "print(\"=\"*55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "fce6939a-83b7-4473-ae74-0364c62db908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1 historical samples\n",
      "Processed 101 historical samples\n",
      "Processed 201 historical samples\n",
      "Processed 301 historical samples\n",
      "Processed 401 historical samples\n",
      "Processed 501 historical samples\n",
      "Processed 601 historical samples\n",
      "Processed 701 historical samples\n",
      "Processed 801 historical samples\n",
      "Processed 901 historical samples\n",
      "Processed 1001 historical samples\n",
      "Processed 1101 historical samples\n",
      "Processed 1201 historical samples\n",
      "Processed 1301 historical samples\n",
      "Processed 1401 historical samples\n",
      "Processed 1501 historical samples\n",
      "Processed 1601 historical samples\n",
      "Processed 1701 historical samples\n",
      "Processed 1801 historical samples\n",
      "Processed 1901 historical samples\n",
      "Processed 2001 historical samples\n",
      "Processed 2101 historical samples\n",
      "Online model initialized with 2200 historical samples\n",
      "\n",
      "==================================================\n",
      "IoT CROP RECOMMENDATION SYSTEM ACTIVATED\n",
      "Initial Model Loaded | Continuous Learning Active\n",
      "==================================================\n",
      "\n",
      "==============================\n",
      "DAY 1 - MORNING READING\n",
      "==============================\n",
      "Sensor Readings:\n",
      "- N: 81.6\n",
      "- P: 116.93\n",
      "- K: 97.39\n",
      "- temperature: 37.39\n",
      "- humidity: 81.21\n",
      "- ph: 9.43\n",
      "- rainfall: 281.66\n",
      "\n",
      "==================================================\n",
      "Recommended crop: rice\n",
      "==================================================\n",
      "\n",
      "==============================\n",
      "DAY 2 - MORNING READING\n",
      "==============================\n",
      "Sensor Readings:\n",
      "- N: 82.93\n",
      "- P: 118.08\n",
      "- K: 99.77\n",
      "- temperature: 38.96\n",
      "- humidity: 81.31\n",
      "- ph: 9.67\n",
      "- rainfall: 278.52\n",
      "\n",
      "==================================================\n",
      "Recommended crop: rice\n",
      "==================================================\n",
      "\n",
      "==============================\n",
      "DAY 3 - MORNING READING\n",
      "==============================\n",
      "Sensor Readings:\n",
      "- N: 87.36\n",
      "- P: 115.9\n",
      "- K: 94.73\n",
      "- temperature: 40.91\n",
      "- humidity: 88.64\n",
      "- ph: 9.08\n",
      "- rainfall: 279.22\n",
      "\n",
      "==================================================\n",
      "Recommended crop: rice\n",
      "==================================================\n",
      "\n",
      "FARMER FEEDBACK RECEIVED\n",
      "Farmer planted: rice\n",
      "Model updated with new data!\n",
      "\n",
      "==============================\n",
      "DAY 4 - MORNING READING\n",
      "==============================\n",
      "Sensor Readings:\n",
      "- N: 81.17\n",
      "- P: 108.64\n",
      "- K: 92.51\n",
      "- temperature: 39.41\n",
      "- humidity: 86.44\n",
      "- ph: 9.29\n",
      "- rainfall: 274.02\n",
      "\n",
      "==================================================\n",
      "Recommended crop: rice\n",
      "==================================================\n",
      "\n",
      "==============================\n",
      "DAY 5 - MORNING READING\n",
      "==============================\n",
      "Sensor Readings:\n",
      "- N: 87.56\n",
      "- P: 117.09\n",
      "- K: 96.36\n",
      "- temperature: 40.07\n",
      "- humidity: 84.7\n",
      "- ph: 9.34\n",
      "- rainfall: 271.5\n",
      "\n",
      "==================================================\n",
      "Recommended crop: rice\n",
      "==================================================\n",
      "\n",
      "==============================\n",
      "DAY 6 - MORNING READING\n",
      "==============================\n",
      "Sensor Readings:\n",
      "- N: 80.62\n",
      "- P: 111.93\n",
      "- K: 94.01\n",
      "- temperature: 40.12\n",
      "- humidity: 81.73\n",
      "- ph: 9.56\n",
      "- rainfall: 274.29\n",
      "\n",
      "==================================================\n",
      "Recommended crop: rice\n",
      "==================================================\n",
      "\n",
      "FARMER FEEDBACK RECEIVED\n",
      "Farmer planted: rice\n",
      "Model updated with new data!\n",
      "\n",
      "==============================\n",
      "DAY 7 - MORNING READING\n",
      "==============================\n",
      "Sensor Readings:\n",
      "- N: 85.17\n",
      "- P: 111.92\n",
      "- K: 97.58\n",
      "- temperature: 40.05\n",
      "- humidity: 82.85\n",
      "- ph: 9.05\n",
      "- rainfall: 284.33\n",
      "\n",
      "==================================================\n",
      "Recommended crop: rice\n",
      "==================================================\n",
      "\n",
      "System shutdown. Model saved for next session.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \"\"\"Scale sensor features using the fitted scaler\"\"\"\n",
    "        # Convert to 2D array for scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b56f4f-18e4-4975-a319-1f0a8a01356c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
